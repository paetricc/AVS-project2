Architektury Výpočetních Systémů (AVS 2023)
Projekt č. 2 (PMC)
Login: xbartu11

Úloha 1: Paralelizace původního řešení
===============================================================================

1) Kterou ze smyček (viz zadání) je vhodnější paralelizovat a co způsobuje 
   neefektivitu paralelizaci té druhé?

   Vhodnější je paralelizovat vnější smyčku, respektive smyčku z funkce
   marchCubes, jež prochází všechny koordináty 3D prostoru.
   Neefektivitu druhé smyčku způsobuje to, že v případě paralelizace této
   smyčky by byla paralelizován pouze malý úsek kódu, a tak by byla režie
   této paralelizace větší než samotná efektivita této paralelizace.

2) Jaké plánování (rozdělení práce mezi vlákna) jste zvolili a proč? 
   Jaký vliv má velikost "chunk" při dynamickém plánování (8, 16, 32, 64)?

   Zvolil jsem plánování guided neboť oproti plánování dynamic nebo static
   dosahovalo lehce lepších rychlostních výsledků a to i v závislosti na
   různých nastaveních parametru chunk_size pro všechna zmíněná plánování.

   Při dynamickém plánování má velikost "chunk" takový vliv, že čím je
   chunk_size větší, tím je menší synchronizační režie ale zato je hrubší
   vyvážení záteže. V mém případě zvyšující se velikost chunk_size při
   dynamickém plánování neměla na rychlost výpočtu prakticky žádný vliv
   (při některých bězích programu bylo skoro nepostřehnutelné, že při velikosti
   chunk_size=16 je výpočet lehce rychlejší).

3) Jakým způsobem zajišťujete ukládání trojúhelníků z několika vláken současně?

   Ukládání trojúhelníků z několika vláken současně je zajištěno pomocí
   #pragma omp critical, která zajišťuje to, že do vektoru mTriangles v daném
   okamžiku bude ukládat trojúhelník pouze jedno vlákno. Pořadí ukládání avšak
   není zaručeno.

Úloha 2: Paralelní průchod stromem
===============================================================================

1) Stručně popište použití OpenMP tasků ve vašem řešení.
   
   Ve funkci marchCubes je vytvořena paralelní oblast. Následně pomocí 
   #pragma omp single určím, aby právě jedno vlákno "nastartovalo" rekurzi 
   funkce octree() (respektive vytvořilo kořen rekuzivního stromu). Následně je  
   ve funkci octree() prováděna hierarchciká dekompozice prostoru na 8 potomků, 
   respektive je aktuální blok rozdělen do 8bloků o poloviční délce hrany 
   původní krychle. Pro výpočet každého takového bloku je vytvořen "task", ve
   kterém je následně opět volána funkce octree() nad vytvořeným blokem. 
   V případě, že v daném bloku neprochází hledaný povrch (ověříme podmínkou, ze 
   zadaní - funkce isBlockEmpty()), tak je zastavena rekurze aktuálního bloku 
   a je vrácena hodnota 0. Rekurze bloku je rovněž zastavena, pokud je délka
   hrany aktuálního bloku rovna 3 a to tak, že je nad tímto blokem použita
   sekvenční verze vyhodnocování respektive "loop" řešení, přičemž se zde již
   nevytváří nové "tasky". Pomocí #pragma omp taskwait je zajištěno, že je 
   výsledný počet trojúhelníků v daném bloku vrácen pouze v případě, že jsou 
   dokončeny všechny "tasky" (respektive všech 8 podbloků daného bloku). 
   Respektive na vizualizaci je výsledek z bloku(tasku) 0 vrácen až v případě, 
   že jsou vráceny všechny výsledky bloků(tasků) 1 až 8, přičemž každý z těchto 
   bloků(tasků) opět čeká na to až bude mít k dispozici všechny výsledky 
   z jeho potomků atd...

   Vizualizace:      [            0            ]
                     /   /   /   / \   \   \   \
                    /   /   /   /   \   \   \   \
                   [1] [2] [3] [4] [5] [6] [7] [8]
                    :   :   :   :   :   :   :   :

2) Jaký vliv má na vaše řešení tzv. "cut-off"? Je vhodné vytvářet nový
   task pro každou krychli na nejnižší úrovni?

   Vliv na řešení pomocí "cut-off" byl takový, že při vyšších délkách hran 
   diskretizační mřížky došlo k časovému zrychlení výpočtu než u řešení bez 
   "cut-off". Rovněž došlo k zlepšení využitelnosti jader. 
   
   Není vhodné vytvářet nový "task" pro každou krychli na nejnižší úrovni. Neboť 
   režie sekvenčního zpracování překonává přínosy zpracování pomocí "tasků". 
   V mém řešení bylo vhodné vytvářet "tasky" pouze do délky hrany krychle 3, pak 
   již bylo vhodné krychli zpracovat sekvenčním řešením.

3) Jakým způsobem zajišťujete ukládání trojúhelníků z několika vláken současně?

   Ukládání trojúhelníků z několika vláken současně je zajištěno stejně jako při
   paralelizaci původního řešení a to pomocí #pragma omp critical, která
   zajišťuje to, že do vektoru mTriangles v daném okamžiku bude ukládat
   trojúhelník pouze jedno vlákno. Pořadí ukládání avšak není zaručeno.

Úloha 3: Grafy škálování všech řešení
===============================================================================

1) Stručně zhodnoťte efektivitu vytvořených řešení (na základě grafů ŠKÁLOVÁNÍ).

2) V jakém případě (v závislosti na počtu bodů ve vstupním souboru a velikosti 
   mřížky) bude vaše řešení 1. úlohy neefektivní? (pokud takový případ existuje)

3) Je (nebo není) stromový algoritmus efektivnější z pohledu slabého škálování 
   vzhledem ke vstupu?

   Pro menší vstupy není stromový algoritmus z hlediska slabého škálování 
   efektivní.

4) Jaký je rozdíl mezi silným a slabým škálováním?

   Silné škálování se zaměřuje na to, jak se zkracuje doba výpočtu úlohy, když 
   dochází ke zvyšování počtu procesorů, přičemž velikost počítané úlohy zůstává 
   stejná. V ideálním případě by zdvojnásobení počtu procesorů mělo mít za 
   následek dvojinásobné zrychlení výpočtu úlohy.

   Zatímco při slabém škálování se chtějí řešit větší problémy na větším stroji 
   za stejý čas. V ideálním případě by dvojnásobek procesorů by měl umožňovat 
   zpracovávat dvojnásobné ůlohy za stejnou dobu výpočtu.

Úloha 4: Analýza využití jader pomocí VTune
================================================================================

1) Jaké bylo průměrné využití jader pro všechny tři implementace s omezením na 
   18 vláken? Na kolik procent byly využity?
   
   ref:  Průměrné využití bylo  0.997 při omezení na 18 vláken a jádra byla využita na  2.8%. [Effective CPU Utilization:  2.8% ( 0.997 out of 36 logical CPUs)]
   loop: Průměrné využití bylo 17.496 při omezení na 18 vláken a jádra byla využita na 48.6%. [Effective CPU Utilization: 48.6% (17.496 out of 36 logical CPUs)]
   tree: Průměrné využití bylo 16.439 při omezení na 18 vláken a jádra byla využita na 45.7%. [Effective CPU Utilitazion: 45.7% (16.439 out of 36 logical CPUs)]

2) Jaké bylo průměrné využití jader pro všechny tři implementace s využitím 
   všech jader? Na kolik procent se podařilo využít obě CPU?
   
   ref:  Průměrné využití bylo  0.997 při omezení na 36 vláken a jádra byla využita na  2.8%. [Effective CPU Utilization:  2.8% ( 0.997 out of 36 logical CPUs)]
   loop: Průměrné využití bylo 32.524 při omezení na 36 vláken a jádra byla využita na 90.3%. [Effective CPU Utilization: 90.3% (32.524 out of 36 logical CPUs)]
   tree: Průměrné využití bylo 28.020 při omezení na 36 vláken a jádra byla využita na 77.8%. [Effective CPU Utilization: 77.8% (28.020 out of 36 logical CPUs)]

3) Jaké jsou závěry z těchto měření?

   Referenční řešení využívá v průměru pouze jedno jádro neboť nepoužívá 
   paralelizaci a tudíž je průměrné využití jader pro obě omezení vláken shodná. 
   Řešení pomocí "loop" a "tree" již využívá paralelizaci a tudíž jsou již 
   využita další jádra, přičemž řešení pomocí "loop" má lepší využití jader než 
   řešení pomocí "tree".

